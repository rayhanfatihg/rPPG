{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-time rPPG Pipeline (Improved)\n",
    "\n",
    "Rayhan Fatih Gunawan\n",
    "\n",
    "NIM.122140134\n",
    "\n",
    "## Improvements\n",
    "- **POS Algorithm**: Plane-Orthogonal-to-Skin for robust signal extraction.\n",
    "- **Advanced ROI**: Specific regions (Cheeks + Forehead) to reduce noise.\n",
    "- **Visualization**: Real-time signal plotting, Frequency Spectrum, and BPM display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from scipy import signal, fftpack\n",
    "import time\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bandpass_filter(data, fs, lowcut=0.7, highcut=4.0, order=4):\n",
    "    nyquist = 0.5 * fs\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = signal.butter(order, [low, high], btype='band')\n",
    "    return signal.filtfilt(b, a, data)\n",
    "\n",
    "def calculate_bpm(processed_signal, fs):\n",
    "    if len(processed_signal) < fs * 2: # Need at least 2 seconds\n",
    "        return 0.0, None, None\n",
    "    \n",
    "    # FFT\n",
    "    n = len(processed_signal)\n",
    "    freqs = fftpack.fftfreq(n, d=1/fs)\n",
    "    fft_val = np.abs(fftpack.fft(processed_signal))\n",
    "    \n",
    "    # Filter positive frequencies and within range\n",
    "    mask = (freqs > 0.7) & (freqs < 4.0)\n",
    "    valid_freqs = freqs[mask]\n",
    "    valid_fft = fft_val[mask]\n",
    "    \n",
    "    if len(valid_fft) == 0:\n",
    "        return 0.0, None, None\n",
    "        \n",
    "    peak_freq = valid_freqs[np.argmax(valid_fft)]\n",
    "    bpm = peak_freq * 60.0\n",
    "    return bpm, valid_freqs, valid_fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RealTimeRPPG:\n",
    "    def __init__(self, buffer_size=300, fs=30):\n",
    "        self.buffer_size = buffer_size\n",
    "        self.fs = fs\n",
    "        self.times = deque(maxlen=buffer_size)\n",
    "        \n",
    "        # Store RGB signals for POS\n",
    "        self.raw_r = deque(maxlen=buffer_size)\n",
    "        self.raw_g = deque(maxlen=buffer_size)\n",
    "        self.raw_b = deque(maxlen=buffer_size)\n",
    "        \n",
    "        self.filtered_signal = []\n",
    "        self.bpm = 0.0\n",
    "        self.fft_freqs = None\n",
    "        self.fft_val = None\n",
    "        \n",
    "        # MediaPipe Face Mesh\n",
    "        self.mp_face_mesh = mp.solutions.face_mesh\n",
    "        self.face_mesh = self.mp_face_mesh.FaceMesh(\n",
    "            max_num_faces=1,\n",
    "            refine_landmarks=True,\n",
    "            min_detection_confidence=0.5,\n",
    "            min_tracking_confidence=0.5\n",
    "        )\n",
    "        \n",
    "        # ROI Indices (Approximate for Cheeks and Forehead)\n",
    "        self.ROI_INDICES = {\n",
    "            'forehead': [10, 338, 297, 332, 284, 251, 389, 356],\n",
    "            'left_cheek': [330, 347, 423, 426, 427, 373, 374],\n",
    "            'right_cheek': [101, 118, 203, 206, 207, 144, 145]\n",
    "        }\n",
    "        \n",
    "    def get_roi_mean_rgb(self, image, landmarks):\n",
    "        h, w, _ = image.shape\n",
    "        mask = np.zeros((h, w), dtype=np.uint8)\n",
    "        \n",
    "        # Draw all ROIs on the mask\n",
    "        for region, indices in self.ROI_INDICES.items():\n",
    "            region_points = np.array([[landmarks[i].x * w, landmarks[i].y * h] for i in indices], dtype=np.int32)\n",
    "            hull = cv2.convexHull(region_points)\n",
    "            cv2.fillPoly(mask, [hull], 255)\n",
    "            \n",
    "        # Calculate mean of R, G, B in the mask\n",
    "        # cv2.mean returns (B, G, R, A)\n",
    "        mean_vals = cv2.mean(image, mask=mask)\n",
    "        return mean_vals[2], mean_vals[1], mean_vals[0] # R, G, B\n",
    "\n",
    "    def process_pos(self, r_list, g_list, b_list):\n",
    "        # POS Algorithm\n",
    "        r = np.array(r_list)\n",
    "        g = np.array(g_list)\n",
    "        b = np.array(b_list)\n",
    "        \n",
    "        # Normalize\n",
    "        r_mean = np.mean(r)\n",
    "        g_mean = np.mean(g)\n",
    "        b_mean = np.mean(b)\n",
    "        \n",
    "        if r_mean == 0 or g_mean == 0 or b_mean == 0:\n",
    "            return np.zeros(len(r))\n",
    "            \n",
    "        rn = r / r_mean\n",
    "        gn = g / g_mean\n",
    "        bn = b / b_mean\n",
    "        \n",
    "        # Projection\n",
    "        s1 = gn - bn\n",
    "        s2 = gn + bn - 2 * rn\n",
    "        \n",
    "        # Tuning\n",
    "        if np.std(s2) == 0:\n",
    "            alpha = 0\n",
    "        else:\n",
    "            alpha = np.std(s1) / np.std(s2)\n",
    "            \n",
    "        # Combination\n",
    "        h = s1 + alpha * s2\n",
    "        return h\n",
    "\n",
    "    def draw_signal(self, image, signal_data, x, y, w, h, color=(0, 255, 0)):\n",
    "        cv2.rectangle(image, (x, y), (x+w, y+h), (0, 0, 0), -1)\n",
    "        \n",
    "        if len(signal_data) < 2:\n",
    "            return\n",
    "            \n",
    "        min_val = np.min(signal_data)\n",
    "        max_val = np.max(signal_data)\n",
    "        \n",
    "        if max_val - min_val == 0:\n",
    "            return\n",
    "            \n",
    "        norm_signal = (signal_data - min_val) / (max_val - min_val)\n",
    "        \n",
    "        points = []\n",
    "        for i, val in enumerate(norm_signal):\n",
    "            px = int(x + (i / len(signal_data)) * w)\n",
    "            py = int(y + h - (val * h))\n",
    "            points.append((px, py))\n",
    "            \n",
    "        for i in range(1, len(points)):\n",
    "            cv2.line(image, points[i-1], points[i], color, 2)\n",
    "\n",
    "    def draw_fft(self, image, freqs, fft_val, x, y, w, h, color=(255, 0, 255)):\n",
    "        cv2.rectangle(image, (x, y), (x+w, y+h), (0, 0, 0), -1)\n",
    "        \n",
    "        if freqs is None or fft_val is None or len(freqs) < 2:\n",
    "            return\n",
    "        \n",
    "        # Normalize FFT values\n",
    "        max_val = np.max(fft_val)\n",
    "        if max_val == 0:\n",
    "            return\n",
    "            \n",
    "        norm_fft = fft_val / max_val\n",
    "        \n",
    "        # Map frequencies to x-axis (0.7 Hz to 4.0 Hz)\n",
    "        min_freq = 0.7\n",
    "        max_freq = 4.0\n",
    "        \n",
    "        points = []\n",
    "        for i, f in enumerate(freqs):\n",
    "            if f < min_freq or f > max_freq:\n",
    "                continue\n",
    "                \n",
    "            px = int(x + ((f - min_freq) / (max_freq - min_freq)) * w)\n",
    "            py = int(y + h - (norm_fft[i] * h))\n",
    "            points.append((px, py))\n",
    "            \n",
    "        for i in range(1, len(points)):\n",
    "            cv2.line(image, points[i-1], points[i], color, 2)\n",
    "\n",
    "    def run(self):\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        print(\"Starting rPPG with POS... Press 'ESC' to exit.\")\n",
    "        \n",
    "        while cap.isOpened():\n",
    "            success, image = cap.read()\n",
    "            if not success:\n",
    "                break\n",
    "                \n",
    "            image = cv2.flip(image, 1)\n",
    "            rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            h, w, _ = image.shape\n",
    "            \n",
    "            results = self.face_mesh.process(rgb_image)\n",
    "            \n",
    "            if results.multi_face_landmarks:\n",
    "                landmarks = results.multi_face_landmarks[0].landmark\n",
    "                \n",
    "                mr, mg, mb = self.get_roi_mean_rgb(image, landmarks)\n",
    "                \n",
    "                self.times.append(time.time())\n",
    "                self.raw_r.append(mr)\n",
    "                self.raw_g.append(mg)\n",
    "                self.raw_b.append(mb)\n",
    "                \n",
    "                for region, indices in self.ROI_INDICES.items():\n",
    "                    region_points = np.array([[landmarks[i].x * w, landmarks[i].y * h] for i in indices], dtype=np.int32)\n",
    "                    hull = cv2.convexHull(region_points)\n",
    "                    cv2.polylines(image, [hull], True, (255, 255, 0), 1)\n",
    "                \n",
    "                if len(self.raw_r) > self.fs * 2:\n",
    "                    pos_signal = self.process_pos(list(self.raw_r), list(self.raw_g), list(self.raw_b))\n",
    "                    detrended = signal.detrend(pos_signal)\n",
    "                    filtered = bandpass_filter(detrended, self.fs)\n",
    "                    self.filtered_signal = filtered\n",
    "                    self.bpm, self.fft_freqs, self.fft_val = calculate_bpm(filtered, self.fs)\n",
    "                \n",
    "                # Display Info\n",
    "                cv2.putText(image, f'BPM: {self.bpm:.1f}', (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                cv2.putText(image, 'Method: POS', (30, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
    "                \n",
    "                # Draw Signal Graph (Time Domain)\n",
    "                if len(self.filtered_signal) > 0:\n",
    "                    display_signal = self.filtered_signal[-150:] if len(self.filtered_signal) > 150 else self.filtered_signal\n",
    "                    self.draw_signal(image, display_signal, 30, 100, 300, 100)\n",
    "                    cv2.putText(image, 'Pulse Signal', (30, 95), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "                \n",
    "                # Draw FFT Graph (Frequency Domain)\n",
    "                if self.fft_freqs is not None:\n",
    "                    self.draw_fft(image, self.fft_freqs, self.fft_val, 30, 230, 300, 100)\n",
    "                    cv2.putText(image, 'Frequency Spectrum', (30, 225), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 255), 1)\n",
    "            \n",
    "            cv2.imshow('Real-time rPPG (POS)', image)\n",
    "            if cv2.waitKey(5) & 0xFF == 27:\n",
    "                break\n",
    "                \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    rppg = RealTimeRPPG()\n",
    "    rppg.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
